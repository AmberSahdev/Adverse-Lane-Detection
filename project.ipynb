{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imageio\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import scipy.signal\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from darkflow.net.build import TFNet\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATE_IMAGE_ENHANCEMENT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxing(original_img, predictions):\n",
    "    # return a new image with a bounding box over the original image using\n",
    "    # coordinates in predictions\n",
    "    newImage = np.copy(original_img)\n",
    "\n",
    "    for result in predictions:\n",
    "        top_x = result['topleft']['x']\n",
    "        top_y = result['topleft']['y']\n",
    "\n",
    "        btm_x = result['bottomright']['x']\n",
    "        btm_y = result['bottomright']['y']\n",
    "\n",
    "        confidence = result['confidence']\n",
    "        label = result['label'] + \" \" + str(round(confidence, 3))\n",
    "\n",
    "        if confidence > 0.3:\n",
    "            newImage = cv2.rectangle(\n",
    "                newImage, (top_x, top_y), (btm_x, btm_y), (255, 0, 0), 3)\n",
    "            newImage = cv2.putText(\n",
    "                newImage,\n",
    "                label,\n",
    "                (top_x, top_y - 5),\n",
    "                cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                0.8,\n",
    "                (0, 230, 0),\n",
    "                1,\n",
    "                cv2.LINE_AA)\n",
    "\n",
    "    return newImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing cfg/yolo.cfg\n",
      "Loading bin/yolo.weights ...\n",
      "Successfully identified 203934260 bytes\n",
      "Finished in 1.2303831577301025s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "WARNING:tensorflow:From /Users/ambersahdev/Envs/CV_final_project/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "       |        | input                            | (?, 608, 608, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 608, 608, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 304, 304, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 304, 304, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 152, 152, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 152, 152, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 76, 76, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 76, 76, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 19, 19, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 38, 38, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 38, 38, 64)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 19, 19, 256)\n",
      " Load  |  Yep!  | concat [27, 24]                  | (?, 19, 19, 1280)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 19, 19, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 19, 19, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "Running entirely on CPU\n",
      "Finished in 23.085297107696533s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "options = {\"model\": \"cfg/yolo.cfg\",\n",
    "           \"load\": \"bin/yolo.weights\",\n",
    "           \"threshold\": 0.3,\n",
    "           \"gpu\": 0.0,\n",
    "           \"labels\": \"labels.txt\"}\n",
    "\n",
    "tfnet = TFNet(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CAIP2017 - 17th international Conference on Computer Analysis of Images and Patterns\n",
    " \n",
    "A New Image Contrast Enhancement Algorithm using Exposure Fusion Framework\n",
    "\n",
    "Ying, Zhenqiang & Li, Ge & Ren, Yurui & Wang, Ronggang & Wang, Wenmin. (2017). 36-46. 10.1007/978-3-319-64698-5_4. \n",
    "\"\"\"\n",
    "def computeTextureWeights(fin, sigma, sharpness):\n",
    "    dt0_v = np.vstack((np.diff(fin, n=1, axis=0), fin[0, :] - fin[-1, :]))\n",
    "    dt0_h = np.vstack((np.diff(fin, n=1, axis=1).conj().T,\n",
    "                       fin[:, 0].conj().T - fin[:, -1].conj().T)).conj().T\n",
    "\n",
    "    gauker_h = scipy.signal.convolve2d(dt0_h, np.ones((1, sigma)), mode='same')\n",
    "    gauker_v = scipy.signal.convolve2d(dt0_v, np.ones((sigma, 1)), mode='same')\n",
    "\n",
    "    W_h = 1 / (np.abs(gauker_h) * np.abs(dt0_h) + sharpness)\n",
    "    W_v = 1 / (np.abs(gauker_v) * np.abs(dt0_v) + sharpness)\n",
    "\n",
    "    return W_h, W_v\n",
    "\n",
    "\n",
    "def solveLinearEquation(IN, wx, wy, lamda):\n",
    "    [r, c] = IN.shape\n",
    "    k = r * c\n",
    "    dx = -lamda * wx.flatten('F')\n",
    "    dy = -lamda * wy.flatten('F')\n",
    "    tempx = np.roll(wx, 1, axis=1)\n",
    "    tempy = np.roll(wy, 1, axis=0)\n",
    "    dxa = -lamda * tempx.flatten('F')\n",
    "    dya = -lamda * tempy.flatten('F')\n",
    "    tmp = wx[:, -1]\n",
    "    tempx = np.concatenate((tmp[:, None], np.zeros((r, c - 1))), axis=1)\n",
    "    tmp = wy[-1, :]\n",
    "    tempy = np.concatenate((tmp[None, :], np.zeros((r - 1, c))), axis=0)\n",
    "    dxd1 = -lamda * tempx.flatten('F')\n",
    "    dyd1 = -lamda * tempy.flatten('F')\n",
    "\n",
    "    wx[:, -1] = 0\n",
    "    wy[-1, :] = 0\n",
    "    dxd2 = -lamda * wx.flatten('F')\n",
    "    dyd2 = -lamda * wy.flatten('F')\n",
    "\n",
    "    Ax = scipy.sparse.spdiags(np.concatenate(\n",
    "        (dxd1[:, None], dxd2[:, None]), axis=1).T, np.array([-k + r, -r]), k, k)\n",
    "    Ay = scipy.sparse.spdiags(np.concatenate(\n",
    "        (dyd1[None, :], dyd2[None, :]), axis=0), np.array([-r + 1, -1]), k, k)\n",
    "    D = 1 - (dx + dy + dxa + dya)\n",
    "    A = ((Ax + Ay) + (Ax + Ay).conj().T + scipy.sparse.spdiags(D, 0, k, k)).T\n",
    "\n",
    "    tin = IN[:, :]\n",
    "    tout = scipy.sparse.linalg.spsolve(A, tin.flatten('F'))\n",
    "    OUT = np.reshape(tout, (r, c), order='F')\n",
    "\n",
    "    return OUT\n",
    "\n",
    "\n",
    "def tsmooth(img, lamda=0.01, sigma=3.0, sharpness=0.001):\n",
    "    I = cv2.normalize(img.astype('float64'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "    x = np.copy(I)\n",
    "    wx, wy = computeTextureWeights(x, sigma, sharpness)\n",
    "    S = solveLinearEquation(I, wx, wy, lamda)\n",
    "    return S\n",
    "\n",
    "\n",
    "def rgb2gm(I):\n",
    "    if (I.shape[2] == 3):\n",
    "        I = cv2.normalize(I.astype('float64'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "        I = (I[:, :, 0] * I[:, :, 1] * I[:, :, 2])**(1 / 3)\n",
    "\n",
    "    return I\n",
    "\n",
    "\n",
    "def applyK(I, k, a=-0.3293, b=1.1258):\n",
    "    def f(x): return np.exp((1 - x**a) * b)\n",
    "    beta = f(k)\n",
    "    gamma = k**a\n",
    "    J = (I**gamma) * beta\n",
    "    return J\n",
    "\n",
    "\n",
    "def entropy(X):\n",
    "    tmp = X * 255\n",
    "    tmp[tmp > 255] = 255\n",
    "    tmp[tmp < 0] = 0\n",
    "    tmp = tmp.astype(np.uint8)\n",
    "    _, counts = np.unique(tmp, return_counts=True)\n",
    "    pk = np.asarray(counts)\n",
    "    pk = 1.0 * pk / np.sum(pk, axis=0)\n",
    "    S = -np.sum(pk * np.log2(pk), axis=0)\n",
    "    return S\n",
    "\n",
    "\n",
    "def maxEntropyEnhance(I, isBad, a=-0.3293, b=1.1258):\n",
    "    # Esatimate k\n",
    "    tmp = cv2.resize(I, (50, 50), interpolation=cv2.INTER_AREA)\n",
    "    tmp[tmp < 0] = 0\n",
    "    tmp = tmp.real\n",
    "    Y = rgb2gm(tmp)\n",
    "\n",
    "    isBad = isBad * 1\n",
    "    isBad = scipy.misc.imresize(isBad, (50, 50), interp='bicubic', mode='F')\n",
    "    isBad[isBad < 0.5] = 0\n",
    "    isBad[isBad >= 0.5] = 1\n",
    "    Y = Y[isBad == 1]\n",
    "\n",
    "    if Y.size == 0:\n",
    "        J = I\n",
    "        return J\n",
    "\n",
    "    def f(k): return -entropy(applyK(Y, k))\n",
    "    opt_k = scipy.optimize.fminbound(f, 1, 7)\n",
    "\n",
    "    # Apply k\n",
    "    J = applyK(I, opt_k, a, b) - 0.01\n",
    "    return J\n",
    "\n",
    "\n",
    "def Ying_2017_CAIP(img, mu=0.5, a=-0.3293, b=1.1258):\n",
    "    lamda = 0.5\n",
    "    sigma = 5\n",
    "    I = cv2.normalize(img.astype('float64'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Weight matrix estimation\n",
    "    t_b = np.max(I, axis=2)\n",
    "    t_our = cv2.resize(\n",
    "        tsmooth(\n",
    "            scipy.misc.imresize(\n",
    "                t_b,\n",
    "                0.5,\n",
    "                interp='bicubic',\n",
    "                mode='F'),\n",
    "            lamda,\n",
    "            sigma),\n",
    "        (t_b.shape[1],\n",
    "         t_b.shape[0]),\n",
    "        interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Apply camera model with k(exposure ratio)\n",
    "    isBad = t_our < 0.5\n",
    "    J = maxEntropyEnhance(I, isBad)\n",
    "\n",
    "    # W: Weight Matrix\n",
    "    t = np.zeros((t_our.shape[0], t_our.shape[1], I.shape[2]))\n",
    "    for i in range(I.shape[2]):\n",
    "        t[:, :, i] = t_our\n",
    "    W = t**mu\n",
    "\n",
    "    I2 = I * W\n",
    "    J2 = J * (1 - W)\n",
    "\n",
    "    result = I2 + J2\n",
    "    result = result * 255\n",
    "    result[result > 255] = 255\n",
    "    result[result < 0] = 0\n",
    "    return result.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Enhancement using CAIP2017 Algorithm Above\n",
    "if ACTIVATE_IMAGE_ENHANCEMENT:\n",
    "    DATA_DIR = 'data/'\n",
    "    RESULTS_DIR = 'processed_imgs/'\n",
    "    for filename in os.listdir(DATA_DIR):\n",
    "        print(\"Processing \", filename)\n",
    "        src = DATA_DIR + filename\n",
    "        dest = RESULTS_DIR + 'processed_' + filename\n",
    "        img = imageio.imread(src)\n",
    "        result = Ying_2017_CAIP(img)\n",
    "        plt.imsave(dest, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.png\n",
      "9.png\n",
      "14.png\n",
      "15.png\n",
      "17.png\n",
      "16.png\n",
      "12.png\n",
      "13.png\n",
      "11.png\n",
      "10.png\n",
      "21.png\n",
      "20.png\n",
      "22.png\n",
      "23.png\n",
      "18.png\n",
      "24.png\n",
      "25.png\n",
      "19.png\n",
      "4.png\n",
      "5.png\n",
      "7.png\n",
      "6.png\n",
      "2.png\n",
      "3.png\n",
      "1.png\n",
      "0.png\n"
     ]
    }
   ],
   "source": [
    "if ACTIVATE_IMAGE_ENHANCEMENT:\n",
    "    DATA_DIR = 'processed_imgs/'\n",
    "else:\n",
    "    DATA_DIR = 'data/'\n",
    "\n",
    "RESULTS_DIR = 'results/'\n",
    "\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    print(filename)\n",
    "    src = DATA_DIR + filename\n",
    "    dest = RESULTS_DIR + 'boxed_image_' + filename\n",
    "\n",
    "    img = cv2.imread(src)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = tfnet.return_predict(img)\n",
    "\n",
    "    boxed_image = boxing(img, results)\n",
    "\n",
    "    with open(RESULTS_DIR + 'result_' + filename.split('.png')[0] + '.txt', 'w') as f:\n",
    "        json.dump(str(results), f)\n",
    "\n",
    "    plt.imsave(dest, boxed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on Video \n",
    "cap = cv2.VideoCapture('./video_data/test_video.mp4')\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('./video_results/output_test_video.avi',\n",
    "                      fourcc, 20.0, (int(width), int(height)))\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        frame = np.asarray(frame)\n",
    "        results = tfnet.return_predict(frame)\n",
    "\n",
    "        new_frame = boxing(frame, results)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        out.write(new_frame)\n",
    "        # cv2.imshow('frame',new_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV_final_project",
   "language": "python",
   "name": "cv_final_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
